# Architecture & Design Document

## System Overview

The Financial Report Analysis System is a containerized, multi-provider AI application for semantic analysis of financial documents. It follows a **Retrieval-Augmented Generation (RAG)** pattern with runtime credential management.

## Core Design Principles

### ğŸ”’ Security First
- **Zero Credential Storage**: No passwords/keys ever persisted
- **Runtime-Only Credentials**: Stored in memory, discarded after session
- **Audit Everything**: Every query logged with provider and timestamp
- **No External Data**: All context from uploaded files only

### ğŸ“ˆ Scalability
- **Horizontal Scaling**: Multiple app instances behind load balancer
- **Vector Database**: pgvector with HNSW indexing for fast search
- **Connection Pooling**: Reuse database connections efficiently
- **Async Operations**: Batch processing for large document sets

### ğŸ›¡ï¸ Reliability
- **Multi-Provider Fallback**: Switch providers if one fails
- **Error Handling**: Graceful degradation with informative messages
- **Health Checks**: Container health endpoints for monitoring
- **Data Persistence**: PostgreSQL with backup strategy

## Architecture Layers

### 1. Presentation Layer (Gradio UI)
- **Single-Page Application**: Gradio Blocks
- **Four Main Tabs**:
  - Credentials: Input AI provider keys (not stored)
  - Reports: Upload and manage documents
  - Chat: Natural language queries
  - BI Bot: Pre-built financial analyses
- **Real-time Feedback**: Status updates, progress indicators
- **Responsive Design**: Works on desktop/tablet

### 2. Application Layer (Python Services)

#### LLM Provider Abstraction
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Multi-Provider Factory     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”â”‚
â”‚ â”‚ Azure   â”‚ â”‚ Google â”‚ â”‚AWSâ”‚â”‚
â”‚ â”‚ OpenAI  â”‚ â”‚ Gemini â”‚ â”‚BRâ”‚â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features**:
- Unified interface for all providers
- Automatic credential validation
- Provider-specific error handling
- Embedding generation
- Chat response generation
- BI analysis generation

#### Document Processing Pipeline
```
Upload â†’ Validate â†’ Extract â†’ Chunk â†’ Embed â†’ Store
  â†“        â†“         â†“        â†“       â†“      â†“
 File    Format    Text     1000    Vector  DB
        Check     Tables     char
```

**Processors**:
- PDF: Uses PyPDF2 + pdfplumber for text and tables
- Excel: Pandas for structured data extraction
- CSV/JSON: Direct parsing
- DOCX: python-docx for text and tables

#### Embedding Service
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Semantic Search Engine  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Vector similarity      â”‚
â”‚ â€¢ Hybrid search          â”‚
â”‚ â€¢ Top-K retrieval        â”‚
â”‚ â€¢ Chunking strategy      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Capabilities**:
- Stores 1536-dimensional embeddings
- Cosine similarity search
- Keyword filtering support
- Provider re-indexing
- Batch embedding generation

#### Audit Service
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Compliance & Logging   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Query tracking         â”‚
â”‚ â€¢ Provider usage stats   â”‚
â”‚ â€¢ Conversation history   â”‚
â”‚ â€¢ Retention policies     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Logging**:
- Every query: text, provider, model, latency, success
- Every embedding: chunks processed, dimensions, provider
- Usage stats: per-provider aggregation
- Session tracking: conversation correlation

### 3. Data Layer (PostgreSQL + pgvector)

#### Database Schema
```sql
reports
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ filename
â”œâ”€â”€ file_path
â”œâ”€â”€ file_size_bytes
â”œâ”€â”€ file_type
â”œâ”€â”€ upload_date
â”œâ”€â”€ processing_status
â”œâ”€â”€ embedding_provider
â”œâ”€â”€ chunks_created
â””â”€â”€ [FK to audit_logs]

chunks
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ report_id (FK)
â”œâ”€â”€ chunk_text
â”œâ”€â”€ chunk_index
â”œâ”€â”€ page_number
â”œâ”€â”€ section_type
â”œâ”€â”€ embedding (Vector 1536) â­
â”œâ”€â”€ embedding_model
â””â”€â”€ created_at

audit_logs
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ query_text
â”œâ”€â”€ query_type
â”œâ”€â”€ provider_name
â”œâ”€â”€ provider_model
â”œâ”€â”€ processing_time_ms
â”œâ”€â”€ chunks_used
â”œâ”€â”€ success
â”œâ”€â”€ error_message
â”œâ”€â”€ session_id
â””â”€â”€ created_at

conversation_messages
â”œâ”€â”€ id (UUID, PK)
â”œâ”€â”€ session_id
â”œâ”€â”€ message_index
â”œâ”€â”€ role
â”œâ”€â”€ content
â”œâ”€â”€ provider_used
â”œâ”€â”€ model_used
â”œâ”€â”€ chunks_referenced (JSON)
â””â”€â”€ created_at
```

#### Indexing Strategy
```sql
-- Fast vector search (approximate)
CREATE INDEX chunks_embedding_idx 
ON chunks USING hnsw (embedding vector_cosine_ops);

-- Supporting indexes
CREATE INDEX chunks_report_idx ON chunks(report_id);
CREATE INDEX chunks_created_idx ON chunks(created_at);
CREATE INDEX audit_created_idx ON audit_logs(created_at);
CREATE INDEX audit_provider_idx ON audit_logs(provider_name);
```

### 4. Infrastructure Layer (Docker & Networking)

#### Container Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Docker Host Network     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Gradio  â”‚ â”‚ Nginx  â”‚    â”‚
â”‚  â”‚ App:7860â”‚ â”‚:80/:443â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜    â”‚
â”‚       â”‚            â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”    â”‚
â”‚  â”‚  PostgreSQL + pgv   â”‚    â”‚
â”‚  â”‚  vector:5432        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Docker Compose Services
1. **app**: Gradio application (Python 3.11)
2. **postgres**: PostgreSQL 16 + pgvector extension
3. **nginx**: Reverse proxy (SSL termination, rate limiting)

#### Network Communication
- Gradio â†” PostgreSQL: Direct TCP (5432)
- External â†” Nginx: HTTPS (443) / HTTP (80)
- Nginx â†” Gradio: HTTP (7860)
- All services: Internal docker network

## Data Flow

### Chat Query Flow
```
1. User enters question
   â†“
2. Question â†’ Generate embedding (using LLM provider)
   â†“
3. Embedding â†’ Search pgvector for similar chunks
   â†“
4. Top-K chunks â†’ Build context window
   â†“
5. Context + Question â†’ Send to LLM provider
   â†“
6. LLM â†’ Generate response with citations
   â†“
7. Log query to audit trail
   â†“
8. Response â†’ Display in UI with sources
```

### Report Upload Flow
```
1. User selects file
   â†“
2. Validate file type and size
   â†“
3. Extract text and tables
   â†“
4. Split into semantic chunks (1000 char, 200 overlap)
   â†“
5. Generate embeddings for each chunk
   â†“
6. Store embeddings + metadata in PostgreSQL
   â†“
7. Update report status to "ready"
   â†“
8. Log embedding generation to audit trail
```

## Credential Management Strategy

### Current Architecture (No Storage)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Credentials       â”‚
â”‚  (Entered in UI)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ (HTTP POST)
             â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Validation â”‚ â†’ Test with provider
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ (Success)
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Session Memory Object   â”‚
â”‚ (current_session dict)  â”‚
â”‚ - credentials dict      â”‚
â”‚ - provider name         â”‚
â”‚ - model name            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ (In-memory only)
             â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ LLM Calls  â”‚ â†’ Generate embeddings
         â”‚            â”‚ â†’ Chat responses
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ (Session ends)
             â†“
        Credentials discarded
```

### Alternative: Secure Storage (Future)
If credential storage is needed:
```python
# Encryption at rest
from cryptography.fernet import Fernet
cipher = Fernet(encryption_key)
encrypted_creds = cipher.encrypt(credentials.encode())

# Store encrypted, retrieve on login
credential = CredentialModel(
    user_id=user.id,
    provider="azure",
    encrypted_value=encrypted_creds,
    created_at=datetime.utcnow()
)

# Decrypt only in memory when needed
decrypted = cipher.decrypt(stored_encrypted).decode()
```

## Performance Optimization

### Vector Search Optimization
```
Index Type       | Recall | Speed   | Memory |
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
Linear scan      | 100%   | Slow    | Low    â”‚
IVFFlat (100)    | 90%    | Medium  | Medium â”‚
HNSW (m=16)      | 95%    | Fast    | High   â”‚
```

### Recommended for Production
```sql
-- Create HNSW index after initial data loading
CREATE INDEX chunks_embedding_hnsw 
ON chunks USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- Tune search parameters
SET hnsw.ef_search = 100;  -- Higher = more accurate but slower
```

### Batch Processing Strategy
```
1. Collect queries (queue)
2. Batch similar queries
3. Generate embeddings in parallel
4. Cache results for 5 minutes
5. Reduce API calls by 60%
```

## Scaling Strategy

### Vertical Scaling (Add Resources)
```
Single Server:
â”œâ”€â”€ CPU: 4 cores â†’ 8+ cores
â”œâ”€â”€ RAM: 4GB â†’ 16GB+
â”œâ”€â”€ Storage: 50GB â†’ 500GB+
â””â”€â”€ Network: 1Gbps â†’ 10Gbps
```

### Horizontal Scaling (Add Instances)
```
Load Balancer (Nginx)
    â”œâ”€â”€ App Instance 1 (port 7860)
    â”œâ”€â”€ App Instance 2 (port 7861)
    â”œâ”€â”€ App Instance 3 (port 7862)
    â””â”€â”€ App Instance N (port 786N)

All instances â†’ Same PostgreSQL (connection pooling)
```

### Database Optimization
```
Primary Database (Writes)
â””â”€â”€ Read Replicas (Audit logs, Reports listing)

Connection Pool: 25-50 connections per app instance
Max Connections: number_of_app_instances Ã— pool_size
```

## Security Architecture

### Authentication & Authorization
```
Future Implementation:
â”œâ”€â”€ User Registration/Login
â”œâ”€â”€ API Key generation per user
â”œâ”€â”€ Role-based access (Admin/User)
â”œâ”€â”€ Audit logs per user
â””â”€â”€ Rate limiting per user
```

### Encryption Strategy
```
Current (Runtime Only):
â”œâ”€â”€ Credentials never written to disk
â”œâ”€â”€ No database storage of secrets
â”œâ”€â”€ HTTPS only for external communication
â””â”€â”€ Connection pooling over local network

Future (Secure Storage):
â”œâ”€â”€ Encrypt credentials at rest (AES-256)
â”œâ”€â”€ Key management with AWS KMS / Azure Key Vault
â”œâ”€â”€ Rotate keys annually
â””â”€â”€ Audit key access
```

### Data Privacy
```
GDPR Compliance:
â”œâ”€â”€ Audit logs retention: 1 year max
â”œâ”€â”€ Right to deletion: Remove report + chunks + logs
â”œâ”€â”€ Data portability: Export conversations as JSON
â””â”€â”€ Transparency: Show all logged data

CCPA Compliance:
â”œâ”€â”€ Opt-out mechanisms
â”œâ”€â”€ Data sale prohibition
â”œâ”€â”€ Sensitive personal info handling
â””â”€â”€ Consumer notice requirements
```

## Deployment Topology

### Development
```
Developer Laptop
â”œâ”€â”€ Docker Desktop
â”œâ”€â”€ All services in one Compose stack
â”œâ”€â”€ Shared network bridge
â””â”€â”€ SQLite or local PostgreSQL
```

### Staging
```
Cloud VM (e.g., EC2, GCP VM)
â”œâ”€â”€ Docker Swarm or Kubernetes
â”œâ”€â”€ Managed PostgreSQL (AWS RDS, Azure Database)
â”œâ”€â”€ SSL with Let's Encrypt
â””â”€â”€ Monitoring + logging stack
```

### Production
```
Kubernetes Cluster (EKS/AKS/GKE)
â”œâ”€â”€ Multiple Gradio pods (auto-scaling)
â”œâ”€â”€ Managed database (RDS, Azure, Cloud SQL)
â”œâ”€â”€ Managed Redis (for caching)
â”œâ”€â”€ Load balancer (ALB, Azure LB, GCP LB)
â”œâ”€â”€ CDN (CloudFront, Azure CDN, Cloud CDN)
â”œâ”€â”€ Monitoring (Prometheus, Datadog)
â”œâ”€â”€ Logging (ELK, Splunk, CloudWatch)
â””â”€â”€ Backup & DR strategy
```

## Technology Stack Justification

| Component | Choice | Why |
|-----------|--------|-----|
| Frontend | Gradio | Easy UI, no JS needed, perfect for ML apps |
| Backend | Python | Simple, LLM SDKs available, rapid dev |
| Database | PostgreSQL | Mature, pgvector support, reliable |
| Vector Store | pgvector | Integrated with PostgreSQL, easy deployment |
| LLM Providers | Multiple | Avoid vendor lock-in, cost optimization |
| Container | Docker | Standard, reproducible builds |
| Orchestration | Docker Compose | Simple for dev/test, Kubernetes for production |
| Reverse Proxy | Nginx | Lightweight, battle-tested, good rate limiting |

## Cost Breakdown (Monthly Estimate)

### Infrastructure (AWS Example)
```
EC2 (app server, t3.large):        $100
RDS (PostgreSQL, 1TB storage):     $200
Load Balancer:                     $25
NAT Gateway:                       $30
Backup storage:                    $20
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Infrastructure:              $375
```

### AI Provider Costs (1000 queries/day)
```
Embeddings (1000 docs, 1000 tokens):    $2 (Azure)
Chat responses (avg 500 tokens):        $5 (Azure)

Alternative with Google Gemini:        $1 (embedding-001)
Alternative with AWS Bedrock:          $10 (Claude)
```

### Total Monthly Estimate
```
Infrastructure + AI:  $375 + $10 = $385/month (Azure)
                      $375 + $5 = $380/month (Google)
                      $375 + $20 = $395/month (AWS)
```

## Future Enhancements

1. **Multi-User Support**: User authentication, separate audit trails
2. **Custom Models**: Fine-tuning on organization-specific data
3. **Real-time Collaboration**: Multiple users querying same reports
4. **Advanced Visualizations**: Charts, dashboards, trend analysis
5. **Mobile App**: React Native/Flutter client
6. **Compliance Automation**: GDPR/HIPAA/SOC2 audit reports
7. **API Gateway**: REST/GraphQL API for third-party integration
8. **Agent Framework**: AutoGPT-style autonomous analysis
9. **Knowledge Base**: Persistent context across users/organizations
10. **Predictive Analytics**: Forecasting based on historical data

---

**Document Version**: 1.0
**Last Updated**: October 2025
**Architecture Owner**: Platform Engineering Team